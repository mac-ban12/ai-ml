{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Cifar_100.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bu5nLaAqDwm9","colab_type":"text"},"source":["# CIFAR 100 dataset - image classification \n"," \n"]},{"cell_type":"markdown","metadata":{"id":"Ddc_AiPzDwm_","colab_type":"text"},"source":["This is the CIFAR 100 dataset. Main page - https://www.cs.toronto.edu/~kriz/cifar.html \n","\n","This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n","\n","We are using this copy to download:  |  CIFAR_100 = 'https://s3.amazonaws.com/fast-ai-imageclas/cifar100'  \n","\n"]},{"cell_type":"code","metadata":{"id":"kWqktHCTDwnA","colab_type":"code","colab":{}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghQEOLU6E2U7","colab_type":"code","colab":{}},"source":["# Set up fastai for collab \n","!pip uninstall torch torchvision -y\n","!pip install torch==1.4.0 torchvision==0.5.0\n","!curl -s https://course.fast.ai/setup/colab | bash"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCrIUc2uqq6g","colab_type":"text"},"source":["Set up drive access for file storage "]},{"cell_type":"code","metadata":{"id":"CNBF-A3OFian","colab_type":"code","colab":{}},"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive', force_remount=True)\n","#root_dir = \"/content/gdrive/My Drive/\"\n","#base_dir = root_dir + 'fastai-v3/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZksTSYkWDwnF","colab_type":"text"},"source":["Import fastai libs"]},{"cell_type":"code","metadata":{"id":"Oh_MrFu-DwnG","colab_type":"code","colab":{}},"source":["from fastai.vision import *\n","from fastai.metrics import error_rate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TLFzy-XDwnM","colab_type":"code","colab":{}},"source":["bs = 64\n","# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9CBgqHgsDwnP","colab_type":"text"},"source":["## Looking at the data / Data preparation\n"]},{"cell_type":"code","metadata":{"id":"9EcmT8J0DwnW","colab_type":"code","colab":{}},"source":["path = untar_data(URLs.CIFAR_100); path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w25CITv6Dwna","colab_type":"code","colab":{}},"source":["# path.ls()\n","\n","# path_test = path/'test'\n","# path_train = path/'train'\n","\n","# (path_train/'fish').ls()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BxyHvWXqDwnh","colab_type":"text"},"source":["There are 20 main classes in train. Each class has further 5 sub classes each - thus 100 total classes. \n","\n","Take this as multi lable classification? However that may not be a great idea. \n","\n","Try with single lable. Load using data block API. "]},{"cell_type":"code","metadata":{"id":"acR8_Q6wDwno","colab_type":"code","colab":{}},"source":["# data = ImageDataBunch.from_df(path, train_df, ds_tfms=get_transforms(), size=224, bs=bs).normalize(imagenet_stats)\n","tfms = get_transforms(do_flip=False) \n","data = (ImageList.from_folder(path=path).split_by_rand_pct().label_from_folder().add_test_folder().transform(tfms, size=224).databunch())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBvbzwMuDwnr","colab_type":"code","colab":{}},"source":["data.show_batch(rows=3, figsize=(7,6))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKkPu68jDwnu","colab_type":"code","colab":{}},"source":["print(data.classes)\n","len(data.classes),data.c"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhpsQYo5Dwny","colab_type":"text"},"source":["## Training: resnet34"]},{"cell_type":"markdown","metadata":{"id":"lPZjjOJXDwny","colab_type":"text"},"source":["Now we will start training our model. We will use a [convolutional neural network](http://cs231n.github.io/convolutional-networks/) backbone and a fully connected head with a single hidden layer as a classifier. Don't know what these things mean? Not to worry, we will dive deeper in the coming lessons. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 37 outputs).\n","\n","We will train for 4 epochs (4 cycles through all our data)."]},{"cell_type":"code","metadata":{"id":"VOX-ZAM5Dwnz","colab_type":"code","colab":{}},"source":["learn = cnn_learner(data, models.resnet34, metrics=error_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlM2yhAJDwn2","colab_type":"code","colab":{}},"source":["learn.model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_Qm3nhJDwoA","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_FZGCEcDwoH","colab_type":"code","colab":{}},"source":["learn.save('stage-1')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SPgfyGzTDwoQ","colab_type":"text"},"source":["## Results"]},{"cell_type":"markdown","metadata":{"id":"5cEA3N8LDwoR","colab_type":"text"},"source":["Let's see what results we have got. \n","\n","We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. \n","\n","Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour."]},{"cell_type":"code","metadata":{"id":"8StWyEp5DwoS","colab_type":"code","colab":{}},"source":["interp = ClassificationInterpretation.from_learner(learn)\n","\n","losses,idxs = interp.top_losses()\n","\n","len(data.valid_ds)==len(losses)==len(idxs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FI7w1j2Dwoa","colab_type":"code","colab":{}},"source":["interp.plot_top_losses(9, figsize=(15,11))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-N6Yb-1Dwoh","colab_type":"code","colab":{}},"source":["#doc(interp.plot_top_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jwN8QAgLDwoo","colab_type":"code","colab":{}},"source":["interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rR09RDXDwow","colab_type":"code","colab":{}},"source":["interp.most_confused(min_val=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--NtUVNiDwo4","colab_type":"text"},"source":["## Unfreezing, fine-tuning, and learning rates"]},{"cell_type":"markdown","metadata":{"id":"jd0jL0FmDwo7","colab_type":"text"},"source":["Since our model is working as we expect it to, we will *unfreeze* our model and train some more."]},{"cell_type":"code","metadata":{"id":"8lCqqyKmDwo8","colab_type":"code","colab":{}},"source":["learn.unfreeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxZVxdacDwpD","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qV40RQgVDwpN","colab_type":"code","colab":{}},"source":["learn.load('stage-1');"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeVVIxf0DwpU","colab_type":"code","colab":{}},"source":["learn.lr_find()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG48Y0ibDwpc","colab_type":"code","colab":{}},"source":["learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPrSLRgxDwpj","colab_type":"code","colab":{}},"source":["learn.unfreeze()\n","learn.fit_one_cycle(4, max_lr=slice(1e-6,1e-4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Jjno2_zDwpq","colab_type":"text"},"source":["Error rate of ~18%. Let us see if resnet50 helps improve. "]},{"cell_type":"markdown","metadata":{"id":"tLjtmUKFDwpt","colab_type":"text"},"source":["## Training: resnet50"]},{"cell_type":"markdown","metadata":{"id":"hgqh2B6dDwpv","colab_type":"text"},"source":["Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf)).\n","\n","Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's us use larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network will require more GPU memory."]},{"cell_type":"code","metadata":{"id":"-wpQ1BVODwpw","colab_type":"code","colab":{}},"source":["data = (ImageList.from_folder(path=path).split_by_rand_pct().label_from_folder().add_test_folder().transform(tfms, size=224).databunch(bs=bs//2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JopxSIZuDwp3","colab_type":"code","colab":{}},"source":["learn = cnn_learner(data, models.resnet50, metrics=error_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKmWR2ieDwp_","colab_type":"code","colab":{}},"source":["learn.lr_find()\n","learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3Gj6ITzDwqH","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7-5Gq2JDwqp","colab_type":"code","colab":{}},"source":["learn.save('stage-1-50')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEdzf2U9Dwqu","colab_type":"text"},"source":["It's the same ~18.7%. Let's see if full fine-tuning helps:"]},{"cell_type":"code","metadata":{"id":"EptnN9MJDwqw","colab_type":"code","colab":{}},"source":["learn.unfreeze()\n","learn.fit_one_cycle(3, max_lr=slice(1e-3,1e-1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iOwVEWwZDwq0","colab_type":"text"},"source":["If it doesn't, you can always go back to your previous model."]},{"cell_type":"code","metadata":{"id":"km4ddSEEDwq1","colab_type":"code","colab":{}},"source":["learn.load('stage-1-50');"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVz0GlXGDwq6","colab_type":"code","colab":{}},"source":["interp = ClassificationInterpretation.from_learner(learn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1WHT6LXDwq-","colab_type":"code","colab":{}},"source":["interp.most_confused(min_val=2)"],"execution_count":0,"outputs":[]}]}